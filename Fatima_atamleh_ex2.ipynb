{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVmAc6HWTA0H"
      },
      "source": [
        "GitHup\n",
        "https://github.com/FatimaAtamlhe/fatima2.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgyagdU6yOpc",
        "outputId": "ed428271-3d82-4218-edd6-2a83957b5ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neurons in each layer: [82, 75, 53, 13]\n",
            "Epoch 1/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.6363 - loss: 1.1597 - val_accuracy: 0.9385 - val_loss: 0.2181\n",
            "Epoch 2/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.4118 - val_accuracy: 0.9559 - val_loss: 0.1563\n",
            "Epoch 3/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.3198 - val_accuracy: 0.9611 - val_loss: 0.1304\n",
            "Epoch 4/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2760 - val_accuracy: 0.9642 - val_loss: 0.1201\n",
            "Epoch 5/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.2576 - val_accuracy: 0.9678 - val_loss: 0.1113\n",
            "Epoch 6/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2285 - val_accuracy: 0.9705 - val_loss: 0.1048\n",
            "Epoch 7/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.2110 - val_accuracy: 0.9695 - val_loss: 0.1097\n",
            "Epoch 8/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.1991 - val_accuracy: 0.9738 - val_loss: 0.0940\n",
            "Epoch 9/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1878 - val_accuracy: 0.9727 - val_loss: 0.0966\n",
            "Epoch 10/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1811 - val_accuracy: 0.9737 - val_loss: 0.0919\n",
            "Epoch 11/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.1659 - val_accuracy: 0.9731 - val_loss: 0.0931\n",
            "Epoch 12/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9531 - loss: 0.1702 - val_accuracy: 0.9758 - val_loss: 0.0890\n",
            "Epoch 13/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1626 - val_accuracy: 0.9751 - val_loss: 0.0936\n",
            "Epoch 14/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9576 - loss: 0.1561 - val_accuracy: 0.9747 - val_loss: 0.0913\n",
            "Epoch 15/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1537 - val_accuracy: 0.9753 - val_loss: 0.0913\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1028\n",
            "Test loss: 0.0876\n",
            "Test Accuracy: 0.97\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the ID\n",
        "id_number = \"213537582\"\n",
        "\n",
        "# Parse the number of neurons for each fully connected layer from the ID\n",
        "neurons = [\n",
        "    int(id_number[-2:]),   # 82\n",
        "    int(id_number[-4:-2]), # 58\n",
        "    int(id_number[-6:-4]), # 37\n",
        "    int(id_number[-8:-6])  # 13\n",
        "]\n",
        "\n",
        "print(f\"Neurons in each layer: {neurons}\")\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model with best hyperparameters\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),           # Define the input layer explicitly\n",
        "    Flatten(),                       # Flatten the input images\n",
        "    Dense(neurons[0], activation='relu'),  # Layer 1\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(neurons[1], activation='relu'),  # Layer 2\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(neurons[2], activation='relu'),  # Layer 3\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(neurons[3], activation='relu'),  # Layer 4\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(10, activation='softmax')        # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbf91h5QrKFv",
        "outputId": "db0a7026-3f30-4f58-b266-0ee2590c7d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Experiment 1...\n",
            "Experiment 1 - Accuracy: 0.98\n",
            "{'experiment': 1, 'neurons': [150, 100, 50, 10], 'batch_size': 64, 'lr': 0.001, 'activation': 'relu', 'accuracy': '0.98'}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# تحميل بيانات MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "# قائمة لتوثيق نتائج التجارب\n",
        "experiment_results = []\n",
        "\n",
        "# قائمة الإعدادات لتجارب متعددة\n",
        "experiments = [\n",
        "     {\"neurons\": [150, 100, 50, 10], \"batch_size\": 64, \"lr\": 0.001, \"activation\": \"relu\"}\n",
        "    ]\n",
        "\n",
        "# تنفيذ التجارب\n",
        "for i, config in enumerate(experiments):\n",
        "    print(f\"Running Experiment {i+1}...\")\n",
        "    # إعداد النموذج\n",
        "    model = Sequential([\n",
        "        Input(shape=(28, 28)),\n",
        "        Flatten(),\n",
        "        Dense(config[\"neurons\"][0], activation=config[\"activation\"]),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(config[\"neurons\"][1], activation=config[\"activation\"]),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(config[\"neurons\"][2], activation=config[\"activation\"]),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(config[\"neurons\"][3], activation=config[\"activation\"]),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # إعداد المُحسّن مع معدل التعلم\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"lr\"])\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # تدريب النموذج\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=config[\"batch_size\"], validation_split=0.2, verbose=0)\n",
        "\n",
        "    # تقييم النموذج\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Experiment {i+1} - Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "    # تخزين النتائج\n",
        "    experiment_results.append({\n",
        "        \"experiment\": i + 1,\n",
        "        \"neurons\": config[\"neurons\"],\n",
        "        \"batch_size\": config[\"batch_size\"],\n",
        "        \"lr\": config[\"lr\"],\n",
        "        \"activation\": config[\"activation\"],\n",
        "        \"accuracy\": f\"{test_acc:.2f}\"\n",
        "    })\n",
        "\n",
        "# عرض النتائج\n",
        "for result in experiment_results:\n",
        "    print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
